{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics\n",
    "import os\n",
    "from glob import glob\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from tools.voiceActivityDetector import VAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_path = 'https://github.com/pdadial/Speech_Emotion_Recognition_CNN-LSTM/tree/main/Database'\n",
    "\n",
    "audio_paths = glob('{}/**'.format(database_path), recursive=True)\n",
    "audio_paths = [x.replace(os.sep, '/') for x in audio_paths if '.wav' in x]\n",
    "classes = os.listdir(database_path)\n",
    "label_encode = {x:i for i,x in enumerate(classes)}\n",
    "labels = [os.database_path.split(x)[0].split('/')[-1] for x in audio_paths]\n",
    "labels = [label_encode[x] for x in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 16000\n",
    "FRAME_LENGTH = int(0.025*sample_rate)\n",
    "HOP_LENGTH = int(0.25*FRAME_LENGTH)\n",
    "\n",
    "n_classes = len(classes)\n",
    "n_mfccs = 19\n",
    "n_audio = len(audio_paths)\n",
    "X = np.empty((n_audio, n_mfccs + 4), dtype=np.float32)\n",
    "Y = np.empty((n_audio, n_classes), dtype=np.uint8)\n",
    "\n",
    "for i, (path, label) in enumerate(zip(audio_paths, labels)):\n",
    "    audio,_ = librosa.load(path, sr=sample_rate, res_type='fft', offset=0.5)\n",
    "    waveform = VAD(audio, sample_rate, int(db))\n",
    "    waveform_pad = np.zeros((int(sample_rate*5,)))\n",
    "    waveform_pad[:len(waveform)] = waveform\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=waveform_pad, sr=sample_rate, n_mfcc=n_mfccs, n_fft=1024, win_length=FRAME_LENGTH, hop_length=HOP_LENGTH, window='hamming', n_mels=128, fmax=sample_rate/2).T,axis=0)\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=waveform_pad, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH))\n",
    "    rmse = np.mean(librosa.feature.rms(y=waveform_pad, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH))\n",
    "    pitch, magnitude = librosa.piptrack(y=waveform, sr=sample_rate, n_fft=1024, hop_length=HOP_LENGTH, win_length=FRAME_LENGTH, window='hamming')\n",
    "    pitch = np.mean(pitch[np.where(magnitude > 0)])\n",
    "    centroid = np.mean(librosa.feature.spectral_centroid(y=waveform, sr=sample_rate, n_fft=1024, hop_length=HOP_LENGTH, win_length=FRAME_LENGTH, window='hamming'))\n",
    "    X[i,...] = np.append(mfccs, (rmse, centroid, zcr, pitch))\n",
    "    Y[i,...] = to_categorical(label, num_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X = X[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.05, random_state=42)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.025, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv1D(filters=32, kernel_size=9, strides=1, padding='same', input_shape=(n_mfccs + 4, 1)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('elu'),\n",
    "        tf.keras.layers.MaxPool1D(pool_size=2, strides=2),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "        tf.keras.layers.Conv1D(filters=64, kernel_size=7, strides=1, padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('elu'),\n",
    "        tf.keras.layers.MaxPool1D(pool_size=2, strides=2),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "        tf.keras.layers.Conv1D(filters=128, kernel_size=5, strides=1, padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('elu'),\n",
    "        tf.keras.layers.MaxPool1D(pool_size=2, strides=2),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "        tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    \n",
    "        tf.keras.layers.Flatten(),\n",
    "        \n",
    "        tf.keras.layers.Dense(units=n_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD(learning_rate=0.01, decay=1e-3, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=64, epochs=1500, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_test, Y_test)\n",
    "print(\"Model Accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "if int(db) == 1:\n",
    "    class_names = ['anger', 'calm', 'disgust', 'fear', 'happiness', 'neutral', 'sadness', 'surprised']\n",
    "else:\n",
    "    class_names = ['anger', 'disgust', 'fear', 'happiness', 'neutral', 'sadness', 'surprised']\n",
    "    \n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(np.argmax(Y_test,axis=1), y_pred)\n",
    "confusion_matrix = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)\n",
    "\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
